{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e62a3aa",
   "metadata": {},
   "source": [
    "# 8장 불변 특징의 표현과 정합 - Images stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac0d79",
   "metadata": {},
   "source": [
    "# ▶ 이미지 스티칭\n",
    "- 사진 이어 붙이기, 파노라마 영상(panorama image)\n",
    "- 방법\n",
    "    - 여러 장의 영상에서 특징점을 검출\n",
    "    - 동일한 특징점 찾기(매칭)\n",
    "    - 투시변환을 이용하여 붙이기(영상 결합)\n",
    "    - 노출 보정, 블렌딩을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0add64",
   "metadata": {},
   "source": [
    "# ▶ OpenCV\n",
    "- Images stitching\n",
    "    - https://docs.opencv.org/4.x/d1/d46/group_stitching.html\n",
    "- Stitcher Class Reference\n",
    "    - cv2.Stitcher_create() -> retval\n",
    "    - cv.Stitcher.stitch(images) -> retval, pano\n",
    "        - images: Input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113828ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f354e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the current working directory\n",
    "os.chdir(r'C:\\Users\\sse88\\Downloads')\n",
    "\n",
    "### 입력 영상 이름\n",
    "img_names = ['hnu_20220530_01.jpg', 'hnu_20220530_02.jpg']\n",
    "\n",
    "### 영상 저장\n",
    "imgs = []\n",
    "for name in img_names:\n",
    "    img = cv2.imread(name)\n",
    "    \n",
    "    if img is None:\n",
    "        print('Image load failed!')\n",
    "        sys.exit()\n",
    "    \n",
    "    imgs.append(img)\n",
    "\n",
    "### 이미지 스티칭\n",
    "stitcher = cv2.Stitcher_create()\n",
    "status, dst = stitcher.stitch(imgs)\n",
    "\n",
    "if status != cv2.Stitcher_OK:\n",
    "    print('Stitch failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cv2.imwrite('output.jpg', dst)\n",
    "\n",
    "cv2.namedWindow('dst', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae41b6d",
   "metadata": {},
   "source": [
    "# ▶ 파노라마 사진 생성기\n",
    "- https://blog.naver.com/PostView.naver?blogld=teach3450&logNo=221983420407\n",
    "- 힌트\n",
    "    - 따로 찍은 2장의 사진 중에 좌측과 우측에 연결한 순서를 정한다.\n",
    "    - 각각 특징점과 디스크립터를 구해 매칭기로 우측사진을 기준으로 좌측사진을 매칭한다.\n",
    "    - 원근 변환행렬을 구해 cv2.warpPerspective() 함수로 원근변환한다.\n",
    "    - 결과 영상 크기를 지정할 때 2개의 영상을 더한 크기를 지정해 그 결과에 좌측 원본사진을 합성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3183a0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-11d9acbc09a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# SIFT 특징 검출기 생성 및 특징점 검출\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdescriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# SIFT 추출기 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkpsL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 키포인트, 디스크립터\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkpsR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaturesR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescriptor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 키포이트, 디스크립터\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "import numpy as np, cv2\n",
    "# 왼쪽/오른쪽 사진 읽기\n",
    "# 왼쪽 사진 = train = 매칭의 대상\n",
    "imgL = cv2.imread(\"hnu_20220530_01.jpg\")\n",
    "# 오른쪽 사진 = query = 매칭의 기준\n",
    "imgR = cv2.imread(\"hnu_20220530_02.jpg\")\n",
    "hl, wl = imgL.shape[:2] # 왼쪽 사진 높이, 넓이\n",
    "hr, wr = imgR.shape[:2] # 오른쪽 사진 높이, 넓이\n",
    "grayL = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY) # 그레이 스케일 변환\n",
    "grayR = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY) # 그레이 스케일 변환\n",
    "\n",
    "# SIFT 특징 검출기 생성 및 특징점 검출\n",
    "descriptor = cv2.xfeatures2d.SIFT_create() # SIFT 추출기 생성\n",
    "(kpsL, featuresL) = descriptor.detectAndCompute(imgL, None) # 키포인트, 디스크립터\n",
    "(kpsR, featuresR) = descriptor.detectAndCompute(imgR, None) # 키포이트, 디스크립터\n",
    "\n",
    "# BF 매칭기 생성 및 knn 매칭\n",
    "matcher = cv2.DescriptorMatcher_create(\"BruteForce\") # BF 매칭기 생성\n",
    "matches = matcher.knnMatch(featuresR, featuresL, 2) # knn 매칭\n",
    "\n",
    "# 좋은 매칭점 선별\n",
    "good_matches = []\n",
    "for m in matches:\n",
    "    if len(m) == 2 and m[0].distance < m[1].distance * 0.75: ### 75%\n",
    "        good_matches.append((m[0].trainIdx, m[0].queryIdx))\n",
    "print('matches:{}/{}'.format(len(good_matches), len(matches)))\n",
    "\n",
    "# 좋은 매칭점이 4개 이상인 원근 변환행렬 구하기\n",
    "if len(good_matches) > 4:\n",
    "    ptsL = np.float32([kpsL[i].pt for (i,_) in good_matches]) # 좋은 매칭점 좌표\n",
    "    ptsR = np.float32([kpsR[i].pt for (_,i) in good_matches]) # 좋은 매칭점 좌표\n",
    "    mtrx, status = cv2.findHomography(ptsR, ptsL, cv2.RANSAC, 4.0)\n",
    "    # 원근 변환행렬로 오른쪽 사진을 원근 변환, 결과 이미지 크기는 사진 2장 크기\n",
    "    panorama = cv2.warpPerspective(imgR, mtrx, (wr + wl, hr))\n",
    "    # 왼쪽 사진을 원근 변환한 왼쪽 영역에 합성\n",
    "    panorama[0:hl, 0:wl] = imgL\n",
    "else: # 좋은 매칭점이 4개가 안 되는 경우\n",
    "    panorama = imgL\n",
    "\n",
    "# 결과 출력\n",
    "cv2.imshow('Left Image', imgL)\n",
    "cv2.imshow('Right Image', imgR)\n",
    "cv2.imshow('Panorama', panorama)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31567a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
